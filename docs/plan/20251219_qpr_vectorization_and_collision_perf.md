# 性能改善プラン: Q_pr ベクトル化と衝突ステップ高速化

> **作成日**: 2025-12-19  
> **対象**: `radiation.qpr_lookup` 補間コスト削減、PSD サイズドリフト移流の Numba 化、フラグメントテンソルキャッシュ拡大、衝突カーネル/IMEX ソルバーのワークスペース再利用

---

## 背景と目標

- 直近のプロファイルで `radiation.qpr_lookup → tables.interp` が累積時間の約 20% を占めるケースを確認。温度・サイズがステップごとにほぼ一定でも 2D 補間が毎回発生している。
- `psd.apply_uniform_size_drift` は Python ループ＋`np.searchsorted` で自己時間が目立つ。Numba 化または完全ベクトル化で削減余地がある。
- フラグメントテンソル `_fragment_tensor` は `v_rel` がスカラーの場合のみ `_FRAG_CACHE` が効いているが、キャッシュ上限が 8 でヒット率が頭打ち。
- 衝突カーネル/IMEX は PSD 依存のため「完成品キャッシュ」は効きづらいが、サイズ依存の前計算とワークバッファ再利用で算術・アロケーションを減らせる。

**達成指標 (最低ライン)**  
- ベース設定（`configs/base.yml`、`t_end_years=0.01`、`n_bins=40`）で `python -m cProfile -o profile.out -m marsdisk.run --config ...` を再計測し、`qpr_lookup` の累積時間を 30%以上削減。  
- 40bin・1万ステップ相当のマイクロベンチで `apply_uniform_size_drift` の 1 ステップあたり実行時間を 50%以上削減。  
- `_FRAG_CACHE_MAX=32` へ拡大してもメモリが問題化しないことを確認（キャッシュヒット率上昇と合わせて定性確認）。

---

## 今回の修正ポイント（評価フィードバック反映）
- 既に `run_zero_d` が `radiation.qpr_cache` を YAML から受け取っており、キャッシュ設定用の追加 CLI フックは不要。Q_pr 高速化は「配列版ルックアップ＋温度変化時のみ再計算」の導線を優先する。
- β≈0.5 近傍での量子化キャッシュ誤差が case_status/Σ に波及するため、`round_tol` はデフォルト off（None）のままにし、許容誤差（相対 ≤1e-4 など）を計測してから opt-in 設定として記録する。
- `apply_uniform_size_drift` はエイリアス更新・質量正規化を内包しているため、Numba/ベクトル化版は同じ I/F と mass_ratio/diagnostics を満たす回帰テストを先行させる。
- `_FRAG_CACHE` はスカラー `v_rel` のときだけ効く。ヒット率改善を検証する際は「`v_rel` スカラー＋固定サイズ配列」条件を明示し、行列入力ケースでは効果が限定的であることを注記する。
- 衝突カーネル前計算は `H`・`N`・`v_rel` 更新イベントでの再生成が必須。毎ステップ変動する量を固定前提にすると不正確になるため、無条件キャッシュは避ける。

## Plan A: Q_pr 補間のベクトル化／キャッシュ強化

1) **配列版ルックアップの追加**  
   - `radiation.qpr_lookup_array(s_arr, T_M, table=None)`（新規）を追加し、`tables.interp_qpr` をまとめて呼び出す形にする。  
   - 温度が一定のステップでは `s` 方向の 1D 補間を先に行い、T に対する線形補間をブロック演算で処理する。  
   - `run_zero_d` ループ内で「温度が変わった時だけ再計算」するキャッシュを持ち、サイズ配列は初期化時に渡す。

2) **量子化キャッシュのチューニング**  
   - 既存の `radiation.qpr_cache` 設定を用い、デフォルトは `round_tol=None`（量子化しない）を維持する。  
   - 量子化を有効化する場合は β≈0.5 近傍の最大誤差を計測して許容範囲を文書化した上で opt-in とする（例: `round_tol=1e-4` で相対誤差≦1e-4 なら許容）。  
   - キャッシュヒット率・`tables.interp_qpr` 呼び出し回数を計測し、ボトルネックがミス率なのか補間自体なのかを切り分ける。

3) **テストと計測**  
   - 単体: 既存 `tests/integration/test_qpr_lookup.py` を拡張し、配列版の補間とキャッシュ量子化の精度を確認。  
   - ベンチ: ベクトル化前後で 1 万件ルックアップの実時間比較を doctest 風に記録。  
   - プロファイル: `configs/base.yml` で cProfile を取り、`qpr_lookup` の累積時間と呼び出し回数を記録する。

---

## Plan B: PSD 一律サイズドリフトの Numba 化

1) **純関数化と JIT 化**  
   - `apply_uniform_size_drift` 内のループを切り出し、`numba.njit(parallel=True)` で実装（引数は `sizes, widths, number, edges, ds_dt, dt, floor`）。  
   - 戻り値で `new_number, new_sizes` を返し、呼び出し側で `psd_state` を更新。JIT 不可環境では従来の NumPy 実装をフォールバック。

2) **ベクトル化フォールバック**  
   - Numba が使えない環境でも速くするため、`np.searchsorted`＋`np.add.at` による全ベクトル化版をフォールバックとして用意。

3) **テストと計測**  
   - 既存の質量保存・床クリップ挙動をカバーするユニットテストを追加し、`mass_ratio`・`sigma_*`・`diagnostics["ds_step"]` が現行実装と一致することを確認。  
   - 40bin×1万ステップのマイクロベンチで Numba・フォールバックの双方を計測し、基準に達することをログ化。

---

## Plan C: フラグメントテンソルキャッシュ拡大と安全性確認

1) `_FRAG_CACHE_MAX` を 8 → 32 へ拡大し、`v_rel` スカラー・サイズ配列固定ケースでヒット率を上げる。  
2) `_fragment_tensor` がキャッシュから返す `Y` を呼び出し側で破壊的に変更していないか確認（必要ならコピーを明示）。  
3) メモリ影響を確認する簡易ベンチ（40–60 bin で 32 エントリ）を実施し、常識的なメモリ使用量であることを記録。行列 `v_rel` ではキャッシュ非適用である点を明記。

---

## Plan D: 衝突カーネル／IMEX のワークスペース再利用

1) **サイズ依存の前計算**  
   - `compute_collision_kernel_C1` のうちサイズのみで決まる項（`s_sum`, `delta`, `area_prefactor` など）を初期化時に前計算し、`H`・`v_rel`・`N` が変わったタイミングで再計算する（無条件キャッシュは禁止）。
2) **ワークバッファの使い回し**  
   - `smol.step_imex_bdf1_C3` で `gain`, `loss`, `source` を事前確保した配列に上書きするインターフェースを追加し、毎ステップのアロケーションを削減。  
   - `np.einsum` を Numba 化する際も同じワーク配列を流用し、GC 圧を下げる。
3) **キャッシュ不適合の明文化**  
   - PSD と H が毎ステップ変わるため「完成品カーネルのキャッシュ」は行わない方針をドキュメント化（このプラン文書を根拠にする）。

---

## リスクとフォールバック

- Q_pr 量子化キャッシュは精度劣化を伴うため、デフォルトは従来通り。精度要求が厳しい計算では `round_tol=None` で無効化できることを保証する。
- Numba 依存を強める箇所は、CI やデバッグ時に `MARSDISK_DISABLE_NUMBA=1` でフォールバックが確実に動くよう維持する。
- ワークスペース再利用で in-place バグが紛れないよう、単体テストで数値同等性を比較する。

---

## 推奨実施順

1. Plan A (Q_pr ベクトル化＋キャッシュ設定) を実装・プロファイル。  
2. Plan B (サイズドリフト Numba/ベクトル化) を実装しマイクロベンチ・単体追加。  
3. Plan C (フラグメントキャッシュ拡大と安全確認) を適用。  
4. Plan D (衝突カーネル前計算＋ワークバッファ再利用) を適用し、再度 cProfile を取得。  
5. すべて完了後に `docs/plan/` へ結果を追記し、`analysis` 側に反映が必要なら DocSync 手順を検討。

## 実装進捗
- [x] Plan A: Q_pr 配列版ルックアップと温度変化時キャッシュ（`qpr_lookup_array` 追加、`run_zero_d` で温度変化時のみ PSD サイズ配列を再評価）
- [x] Plan B: `apply_uniform_size_drift` のベクトル化／Numba リビン実装と回帰テスト追加
- [x] Plan C: `_FRAG_CACHE_MAX` 拡大とキャッシュ安全化（読み取り専用格納）
- [x] Plan D: 衝突カーネルサイズ項の前計算ワークスペースと IMEX ワークバッファ再利用
